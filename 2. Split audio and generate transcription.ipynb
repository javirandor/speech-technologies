{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split audio and generate transcription\n",
    "\n",
    "Using the previosly generated transcriptions, this will split our dataset into training and test sets. Then, it will create a unique transcription file for the available sentences and a unique audio file for each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pydub import AudioSegment\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "from math import floor\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 40 audio files\n"
     ]
    }
   ],
   "source": [
    "transcriptions_directory = './transcriptions'\n",
    "audio_files = []\n",
    "\n",
    "for file in os.listdir(transcriptions_directory):\n",
    "    filename = os.fsdecode(file)\n",
    "    if (filename.endswith('.json')):\n",
    "        audio_files.append(filename.replace('.json', ''))\n",
    "\n",
    "print('There are {} audio files'.format(len(audio_files)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_sec_to_miliseconds (time):\n",
    "    p = re.compile('\\d+')\n",
    "    numbers = p.findall(time)\n",
    "    minutes = int(numbers[0])\n",
    "    seconds = int(numbers[1])\n",
    "    return (60*minutes+seconds)*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sentences (audio_file, path):\n",
    "    with open(path+audio_file+'.json') as f:\n",
    "        sentences = json.loads(f.read())\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_sentence (sentence, transcription_file, audio_file):\n",
    "    with open(transcription_file, \"a\") as f:\n",
    "        for s in sentence['sentences']:\n",
    "            f.write(\"<s> {} </s> ({})\\n\".format(s, audio_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_audio_trans (audio_file, sentences, inpath, outpath, transcription_file, padding, fileids):\n",
    "\n",
    "    # Read audio file from mp3\n",
    "    print(inpath+audio_file)\n",
    "    readAudio = AudioSegment.from_mp3(inpath+audio_file)\n",
    "    \n",
    "    # Set frame rate to 16kHz\n",
    "    audioFR = readAudio.set_frame_rate(16000)\n",
    "    audioFR = audioFR.set_channels(1)\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        start_time = int(min_sec_to_miliseconds(sentence['start_time']))\n",
    "        end_time = int(min_sec_to_miliseconds(sentence['end_time']) + padding*1000)\n",
    "        fragment = audioFR[start_time:end_time]\n",
    "        \n",
    "        # Store audio fragment\n",
    "        out = fragment.export(outpath + '{}_{}_{}.wav'.format(audio_file, start_time, end_time), format=\"wav\")\n",
    "        fileids.write('{}_{}_{}\\n'.format(audio_file, start_time, end_time))\n",
    "        \n",
    "        store_sentence(sentence, transcription_file, '{}_{}_{}'.format(audio_file, start_time, end_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folders(audio_file, path):\n",
    "    try:\n",
    "        if os.path.isdir(path+audio_file):\n",
    "            shutil.rmtree(path+audio_file)\n",
    "        \n",
    "        os.mkdir(path+audio_file)\n",
    "        os.mkdir(path+audio_file+'/audios')\n",
    "        \n",
    "    except:\n",
    "        print('Error creating folders for {}'.format(audio_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_test_train (filenames: list, \n",
    "                      test_size: float):\n",
    "    \"\"\"\n",
    "    Divides a given list of file names into train and test set using the desired proportion for the test. It shuffles\n",
    "    the input to avoid patterns in input order.\n",
    "    \n",
    "    :param filenames: list of the files that is going to be splitted\n",
    "    :param test_size: proportion between 0 and 1 that will be used for test set\n",
    "    \n",
    "    :return train, test: lists containing filenames for training and testing respectively\n",
    "    \"\"\"\n",
    "    try:\n",
    "        shuffle(filenames)\n",
    "        train_len = floor(len(filenames)*(1-test_size))\n",
    "\n",
    "        train = filenames[:train_len]\n",
    "        test = filenames[train_len:]   \n",
    "\n",
    "        return train, test\n",
    "    \n",
    "    except:\n",
    "        print(\"Error dividing dataset!\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_audio, test_audio = split_test_train(audio_files, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing [0/32]: KORWB1.mp3\n",
      "./audios/KORWB1.mp3\n",
      "Processing [1/32]: POLMB1.mp3\n",
      "./audios/POLMB1.mp3\n",
      "Processing [2/32]: DUTMA2.mp3\n",
      "./audios/DUTMA2.mp3\n",
      "Processing [3/32]: HUNWA2.mp3\n",
      "./audios/HUNWA2.mp3\n",
      "Processing [4/32]: CHIWA2_2.mp3\n",
      "./audios/CHIWA2_2.mp3\n",
      "Processing [5/32]: DUTWA2_2.mp3\n",
      "./audios/DUTWA2_2.mp3\n",
      "Processing [6/32]: FINWA2.mp3\n",
      "./audios/FINWA2.mp3\n",
      "Processing [7/32]: FREMA2.mp3\n",
      "./audios/FREMA2.mp3\n",
      "Processing [8/32]: ITAMA2.mp3\n",
      "./audios/ITAMA2.mp3\n",
      "Processing [9/32]: PORMA2.mp3\n",
      "./audios/PORMA2.mp3\n",
      "Processing [10/32]: POLWB1.mp3\n",
      "./audios/POLWB1.mp3\n",
      "Processing [11/32]: POLMA2_2.mp3\n",
      "./audios/POLMA2_2.mp3\n",
      "Processing [12/32]: ITAWA2.mp3\n",
      "./audios/ITAWA2.mp3\n",
      "Processing [13/32]: ITAMB1.mp3\n",
      "./audios/ITAMB1.mp3\n",
      "Processing [14/32]: CHIMB1.mp3\n",
      "./audios/CHIMB1.mp3\n",
      "Processing [15/32]: FREMB1.mp3\n",
      "./audios/FREMB1.mp3\n",
      "Processing [16/32]: FREWB1.mp3\n",
      "./audios/FREWB1.mp3\n",
      "Processing [17/32]: PORWA2_2.mp3\n",
      "./audios/PORWA2_2.mp3\n",
      "Processing [18/32]: ITAWB1.mp3\n",
      "./audios/ITAWB1.mp3\n",
      "Processing [19/32]: GERWA2.mp3\n",
      "./audios/GERWA2.mp3\n",
      "Processing [20/32]: ENGMB1.mp3\n",
      "./audios/ENGMB1.mp3\n",
      "Processing [21/32]: GERWB1_1.mp3\n",
      "./audios/GERWB1_1.mp3\n",
      "Processing [22/32]: DUTWA2_1.mp3\n",
      "./audios/DUTWA2_1.mp3\n",
      "Processing [23/32]: JAPWB1_1.mp3\n",
      "./audios/JAPWB1_1.mp3\n",
      "Processing [24/32]: POLMA2_1.mp3\n",
      "./audios/POLMA2_1.mp3\n",
      "Processing [25/32]: CHIWA2_1.mp3\n",
      "./audios/CHIWA2_1.mp3\n",
      "Processing [26/32]: GERWB1_2.mp3\n",
      "./audios/GERWB1_2.mp3\n",
      "Processing [27/32]: GERMA2.mp3\n",
      "./audios/GERMA2.mp3\n",
      "Processing [28/32]: DUTWB1.mp3\n",
      "./audios/DUTWB1.mp3\n",
      "Processing [29/32]: FREWA2.mp3\n",
      "./audios/FREWA2.mp3\n",
      "Processing [30/32]: JAPWB1_2.mp3\n",
      "./audios/JAPWB1_2.mp3\n",
      "Processing [31/32]: PORWB1.mp3\n",
      "./audios/PORWB1.mp3\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile('/Users/javirando/Desktop/Universidad/3º/3 Trimestre/Speech/Final Project/models/es-es/trans.transcription'):\n",
    "    os.remove('/Users/javirando/Desktop/Universidad/3º/3 Trimestre/Speech/Final Project/models/es-es/trans.transcription')\n",
    "\n",
    "with open('/Users/javirando/Desktop/Universidad/3º/3 Trimestre/Speech/Final Project/models/es-es/corele.fileids', 'w') as f:\n",
    "    for audio_file in training_audio:\n",
    "        print('Processing [{}/{}]: {}'.format(audio_files.index(audio_file), len(training_audio), audio_file))\n",
    "        padding = 0\n",
    "\n",
    "        if (\"A2\" in audio_file):\n",
    "            padding=1\n",
    "        else:\n",
    "            padding=0.5\n",
    "\n",
    "        sentences = load_sentences(audio_file, './transcriptions/')\n",
    "        split_audio_trans(audio_file, sentences, './audios/', '/Users/javirando/Desktop/Universidad/3º/3 Trimestre/Speech/Final Project/models/es-es/', '/Users/javirando/Desktop/Universidad/3º/3 Trimestre/Speech/Final Project/models/es-es/corele_raw.transcription', padding, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of lines is: 2943\n"
     ]
    }
   ],
   "source": [
    "fname = \"/Users/javirando/Desktop/Universidad/3º/3 Trimestre/Speech/Final Project/models/es-es/corele_raw.transcription\"\n",
    "count = 0\n",
    "with open(fname, 'r') as f:\n",
    "    for line in f:\n",
    "        count += 1\n",
    "print(\"Total number of lines is:\", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ENGWB1_2.mp3',\n",
       " 'JAPWB1_3.mp3',\n",
       " 'PORWA2_1.mp3',\n",
       " 'TURWB1.mp3',\n",
       " 'ENGWA2.mp3',\n",
       " 'ENGWB1_1.mp3',\n",
       " 'JAPWA2.mp3',\n",
       " 'CHIWB1.mp3']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing [32/8]: ENGWB1_2.mp3\n",
      "./audios/ENGWB1_2.mp3\n",
      "Processing [33/8]: JAPWB1_3.mp3\n",
      "./audios/JAPWB1_3.mp3\n",
      "Processing [34/8]: PORWA2_1.mp3\n",
      "./audios/PORWA2_1.mp3\n",
      "Processing [35/8]: TURWB1.mp3\n",
      "./audios/TURWB1.mp3\n",
      "Processing [36/8]: ENGWA2.mp3\n",
      "./audios/ENGWA2.mp3\n",
      "Processing [37/8]: ENGWB1_1.mp3\n",
      "./audios/ENGWB1_1.mp3\n",
      "Processing [38/8]: JAPWA2.mp3\n",
      "./audios/JAPWA2.mp3\n",
      "Processing [39/8]: CHIWB1.mp3\n",
      "./audios/CHIWB1.mp3\n"
     ]
    }
   ],
   "source": [
    "with open('/Users/javirando/Desktop/Universidad/3º/3 Trimestre/Speech/Final Project/models/es-es/corele.fileids', 'w') as f:\n",
    "    for audio_file in test_audio:\n",
    "        print('Processing [{}/{}]: {}'.format(audio_files.index(audio_file), len(test_audio), audio_file))\n",
    "        padding = 0\n",
    "\n",
    "        if (\"A2\" in audio_file):\n",
    "            padding=1\n",
    "        else:\n",
    "            padding=0.5\n",
    "\n",
    "        sentences = load_sentences(audio_file, './transcriptions/')\n",
    "        split_audio_trans(audio_file, sentences, './audios/', '/Users/javirando/Desktop/Universidad/3º/3 Trimestre/Speech/Final Project/models/es-es/test/', '/Users/javirando/Desktop/Universidad/3º/3 Trimestre/Speech/Final Project/models/es-es/corele_raw_test.transcription', padding, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
